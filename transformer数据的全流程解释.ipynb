{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe0bce4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Utilities import Mytokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy,math\n",
    "import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8357a97a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸­æ–‡å­—å…¸å­—æ•° 3643\n",
      "è‹±æ–‡å­—å…¸å­—æ•° 8349\n"
     ]
    }
   ],
   "source": [
    "train_path = '/home/jovyan/input/anki2023_en_ch/train.txt'\n",
    "data_path = '/home/jovyan/input/anki2023_en_ch/cmn.txt'\n",
    "tokenizer = Mytokenizer(data_path,'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd19d8e-f755-4949-a49c-28f92bc7ca26",
   "metadata": {},
   "source": [
    "## è‡ªå®šä¹‰çš„æ•°æ®é›†\n",
    "è¿™ä¸ªæ•°æ®é›†å®ç°äº†å°†æ–‡å­—è½¬id å¹¶ä¸”æ¯ä¸ªè¿‡ç¨‹éƒ½æœ‰å¯¹åº”çš„è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5f9c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    \"\"\"\n",
    "    @file_path æ•°æ®å­˜å‚¨ä½ç½®\n",
    "    @tokenizer å°†æ–‡å­—idåŒ–çš„å®ä¾‹åŒ–åçš„Tokenizer\n",
    "    @æ–‡ä»¶ä¸­ trgæ•°æ®çš„ä½ç½®\n",
    "    \n",
    "    ç”±äºDecoderçš„è¾“å…¥è¦æ±‚ï¼Œä¸€å¥è¯åº”è¢«åˆ‡åˆ†æˆå¤šæ®µï¼Œç›®æ ‡è¯æ•°æœ‰å¤šå°‘å°±åº”åˆ‡åˆ†å¤šå°‘æ¬¡\n",
    "    é‚£ä¹ˆç”¨ä¸€ä¸ªè‡ªå·±å†™åœ¨Transformerä¸­çš„batchç±»å°è£…ä¸€å¥è¯ï¼Œä¼šè‡ªåŠ¨çš„ç»™å¥å­maskï¼Œ\n",
    "    å¹¶ä¸”åˆ‡åˆ†Decoderçš„è¾“å…¥è¾“å‡º,ä½†æ˜¯æ³¨æ„ä¾‹å¦‚:\n",
    "    trgä¸º \"I love food\" é‚£ä¹ˆåº”è¯¥è¾“å…¥å››æ¬¡ï¼Œè¾“å‡ºå››æ¬¡\n",
    "        è¾“å…¥                   è¾“å‡º\n",
    "    <BOS> mask mask mask   I \n",
    "    <BOS> I    mask mask   I love\n",
    "    <BOS> I    love mask   I love food\n",
    "    <BOS> I    love food   I love food <EOS>\n",
    "    \n",
    "    æ–‡ä»¶ä¸­çš„æ ·å­å¦‚ä¸‹ï¼Œä¸­è¯‘è‹±ä»»åŠ¡è‹±æ–‡ä¸ºç›®æ ‡è¯­è¨€ trg_indexåº”ä¸º0\n",
    "    Hi\tå—¨\n",
    "    Hi\tä½  å¥½\n",
    "    Run\tä½  ç”¨ è·‘ çš„\n",
    "    \"\"\"\n",
    "    def __init__(self,file_path,tokenizer,trg_index=0):\n",
    "        self.tokenizer = tokenizer\n",
    "        #è¯»å–æ‰€æœ‰æ–‡æœ¬\n",
    "        with open(file_path,'r',encoding='utf8') as f:\n",
    "            self.lines = f.readlines()\n",
    "        #self.trg_count_words_line = []\n",
    "        self.length = len(self.lines)\n",
    "        self.trg_index = trg_index\n",
    "        if trg_index==0:\n",
    "            self.src_index = 1\n",
    "        else:\n",
    "            self.src_index = 0\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        src = self.lines[index].split('\\t')[self.src_index]\n",
    "        src = src.split('\\n')[0]\n",
    "        print(\"src:\",src)\n",
    "        trg = self.lines[index].split('\\t')[self.trg_index]\n",
    "        print(\"trg:\",trg)\n",
    "        #å¦‚ä¸Šé¢çš„ä¾‹å­ ä¸‰ä¸ªè¯çš„å¥å­åº”æœ‰å››ä¸ªæ ·æœ¬,æ‰€ä»¥åº”è¯¥æ‹·è´ä¸‰æ¬¡\n",
    "        copy_time = len(trg.split(' '))\n",
    "        print(copy_time)\n",
    "        # src_idåŒ– è¿™é‡Œç®€å•å®šä¹‰äº†srcä½¿ç”¨ä¸­æ–‡\n",
    "        src_id = self.tokenizer.ch_token_id([src],len(src.split(' ')))\n",
    "        print(\"src_id:\",src_id)\n",
    "        trg_id = self.tokenizer.en_token_id([trg],len(trg.split(' '))+2)\n",
    "        print(\"trg_id:\",trg_id)\n",
    "        src_tensor = torch.LongTensor(src_id)\n",
    "        trg_tensor = torch.LongTensor(trg_id)\n",
    "        print('src_tensor:',src_tensor.shape,'trg_tensor:',trg_tensor.shape)\n",
    "        #å¤åˆ¶   \n",
    "        #src_tensor = src_tensor.repeat(copy_time+1,1)\n",
    "        #trg_tensor = trg_tensor.repeat(copy_time+1,1)\n",
    "        #print(src_tensor)\n",
    "        #print(trg_tensor)\n",
    "        b = Transformer.Batch(src_tensor,trg_tensor)\n",
    "        print('æ•°æ®æœ€ç»ˆå½¢æ€')\n",
    "        print('è¾“å…¥',b.trg)\n",
    "        print('è¾“å‡º',b.trg_y)\n",
    "        print('mask',b.trg_mask)\n",
    "        return b\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6610eca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23635\n",
      "src: æˆ‘ çœŸ è ¢\n",
      "trg: I'm so stupid\n",
      "3\n",
      "src_id: [[16, 226, 309]]\n",
      "trg_id: [[1, 23, 175, 698, 2]]\n",
      "src_tensor: torch.Size([1, 3]) trg_tensor: torch.Size([1, 5])\n",
      "æ•°æ®æœ€ç»ˆå½¢æ€\n",
      "è¾“å…¥ tensor([[  1,  23, 175, 698]])\n",
      "è¾“å‡º tensor([[ 23, 175, 698,   2]])\n",
      "mask tensor([[[ True, False, False, False],\n",
      "         [ True,  True, False, False],\n",
      "         [ True,  True,  True, False],\n",
      "         [ True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "dataset = Mydataset(train_path,tokenizer)\n",
    "print(len(dataset))\n",
    "b1 = dataset.__getitem__(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce252e",
   "metadata": {},
   "source": [
    "å°†è¦æµ‹è¯•è¾“å…¥è¾“å‡ºçš„æ¨¡å— å®ä¾‹åŒ–æ­¥éª¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a72586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_vocab,trg_vocab = tokenizer.get_vocab()\n",
    "d_model = 512\n",
    "#è¿™æ˜¯ä¸€ä¸ªç®€å•çš„Transformerç½‘ç»œï¼Œåªæœ‰ä¸€å±‚encoder decoder æ³¨ï¼šæ— ç”Ÿæˆå™¨\n",
    "model = Transformer.make_model(src_vocab,trg_vocab,1,d_model)\n",
    "en_embedding = Transformer.Embeddings(d_model,trg_vocab)\n",
    "ch_embedding = Transformer.Embeddings(d_model,src_vocab)\n",
    "multihead_attention = Transformer.MultiHeadedAttention(8,d_model)\n",
    "pe = Transformer.PositionalEncoding(d_model,0.1,max_len=20)\n",
    "generater = Transformer.Generator(d_model,trg_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5a971",
   "metadata": {},
   "source": [
    "## Transformerå„ä¸ªç»“æ„çš„è¾“å…¥è¾“å‡ºæ¨¡æ‹Ÿ\n",
    "é€šè¿‡æœªè®­ç»ƒçš„ç½‘ç»œè¿è¡Œæ•°æ®è·å¾—å¯¹åº”çš„æ•°æ®å½¢çŠ¶\\\n",
    "é¡ºåºä¸ºEmbedding->PositionEncoding->MultiheadAttention\\\n",
    "Encoder-MultiHead è¾“å…¥æ¥æºä¸ºq:src_tensor k:src_tensor v:src_tensor\\\n",
    "Dncoder-MultiHead\\\n",
    "è¾“å…¥æ¥æºä¸º\\\n",
    "1&emsp;q:trg_tensor&emsp;k:trg_tensor&emsp;&emsp;&emsp;v:trg_tensor&emsp;mask:trg_mask\\\n",
    "2&emsp;q:trg_tensor&emsp;k:encoder_output&emsp;v:encoder_output&emsp;mask:src_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca5ebf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddingï¼š torch.Size([1, 3, 512]) torch.Size([1, 4, 512])\n",
      "PositionEncoding: torch.Size([1, 3, 512]) torch.Size([1, 4, 512])\n",
      "torch.Size([1, 1, 3])\n",
      "Encoder-Multihead: torch.Size([1, 3, 512])\n",
      "Decoder-masked-Multihead: torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#è¿™é‡Œæ˜¯æ¨¡æ‹Ÿä¸€ä¸ªæ ·æœ¬è¾“å…¥Transformerå†…éƒ¨æ•°æ®å¤„ç†æµç¨‹ï¼Œå¹¶ä¸”æ‰“å°ä»å„ä¸ªæ¨¡å—å‡ºæ¥çš„æ•°æ®å½¢çŠ¶\n",
    "src_tensor = ch_embedding(b1.src)\n",
    "trg_tensor = en_embedding(b1.trg)\n",
    "print(\"Embeddingï¼š\",src_tensor.shape,trg_tensor.shape)\n",
    "src_tensor = pe(src_tensor)\n",
    "trg_tensor = pe(trg_tensor)\n",
    "print(\"PositionEncoding:\",src_tensor.shape,trg_tensor.shape)\n",
    "print(b1.src_mask.shape)\n",
    "encoder_output = multihead_attention(src_tensor,src_tensor,src_tensor,b1.src_mask)\n",
    "print('Encoder-Multihead:',encoder_output.shape)\n",
    "decoder_output = multihead_attention(trg_tensor,trg_tensor,trg_tensor,b1.trg_mask)\n",
    "decoder_output = multihead_attention(trg_tensor,encoder_output,encoder_output,b1.src_mask)\n",
    "print('Decoder-masked-Multihead:',decoder_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e928bc-a02b-4b73-a638-2153487ef66c",
   "metadata": {},
   "source": [
    "## Transformeræ•´ä½“è¾“å…¥è¾“å‡º\n",
    "è¿™é‡Œæ¨¡æ‹Ÿäº†ä¸€æ¡æ•°æ®åº”è¯¥å¦‚ä½•è¾“å…¥Transformerï¼Œå·²ç»å¯¹åº”çš„è¾“å‡ºåº”è¯¥æ€ä¹ˆå¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd6b12ca-441e-4de6-a2f2-bc6290211e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥æ¨¡å‹çš„æ•°æ®ä¸º(å…¶å®å°±æ˜¯ä¸€å¥è¯å¤åˆ¶äº†å››é):\n",
      " tensor([[ 16, 226, 309],\n",
      "        [ 16, 226, 309],\n",
      "        [ 16, 226, 309],\n",
      "        [ 16, 226, 309]]) \n",
      " tensor([[  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698]])\n",
      "Total Model: torch.Size([4, 4, 512])\n",
      "Generater: torch.Size([4, 4, 8349])\n",
      "ç›®å‰æˆ‘ä»¬å·²ç»è·å¾—äº†å››å¥è¯ï¼Œå››ä¸ªè¯çš„idäº†,å½“ç„¶è¿™å››å¥åº”è¯¥æ˜¯\n",
      "I'm |<PAD>|<PAD>|<PAD>\n",
      "I'm |so | <PAD> |<PAD>\n",
      "I'm |so |stupid |<PAD>\n",
      "I'm |so |stupid |<EOS>\n",
      "é‚£ä¹ˆæˆ‘ä»¬éœ€è¦å°†è¿™å››å¥è¯çš„idåŒ–çš„å‘é‡ä¸generatorçš„è¾“å‡ºè®¡ç®—æŸå¤±\n",
      "ä½†è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œæ¯æ¬¡åªè®¡ç®—ä¸€ä¸ªè¯çš„æŸå¤±ï¼Œå¦‚ç¬¬ä¸€è¡Œåº”è®¡ç®—I'm\n",
      "ç¬¬äºŒè¡Œåº”è®¡ç®—so ä»¥æ­¤ç±»æ¨ å…¶ä»–è¯çš„å·®è·ä¸è¿›è¡Œè®¡ç®—\n"
     ]
    }
   ],
   "source": [
    "trg_input = b1.trg\n",
    "copy_time = trg_input.shape[1]\n",
    "#print(trg_input.shape)\n",
    "trg_input = trg_input.repeat(copy_time,1)\n",
    "src_input = b1.src\n",
    "src_input = src_input.repeat(copy_time,1)\n",
    "print('è¾“å…¥æ¨¡å‹çš„æ•°æ®ä¸º(å…¶å®å°±æ˜¯ä¸€å¥è¯å¤åˆ¶äº†å››é):\\n',src_input,'\\n',trg_input)\n",
    "transformer_output = model(src_input,trg_input,b1.src_mask,b1.trg_mask)\n",
    "print(\"Total Model:\",transformer_output.shape)\n",
    "generater_output = generater(transformer_output)\n",
    "print(\"Generater:\",generater_output.shape)\n",
    "print(\"ç›®å‰æˆ‘ä»¬å·²ç»è·å¾—äº†å››å¥è¯ï¼Œå››ä¸ªè¯çš„idäº†,å½“ç„¶è¿™å››å¥åº”è¯¥æ˜¯\")\n",
    "print(\"I'm |<PAD>|<PAD>|<PAD>\")\n",
    "print(\"I'm |so | <PAD> |<PAD>\")\n",
    "print(\"I'm |so |stupid |<PAD>\")\n",
    "print(\"I'm |so |stupid |<EOS>\")\n",
    "print(\"é‚£ä¹ˆæˆ‘ä»¬éœ€è¦å°†è¿™å››å¥è¯çš„idåŒ–çš„å‘é‡ä¸generatorçš„è¾“å‡ºè®¡ç®—æŸå¤±\")\n",
    "print(\"ä½†è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œæ¯æ¬¡åªè®¡ç®—ä¸€ä¸ªè¯çš„æŸå¤±ï¼Œå¦‚ç¬¬ä¸€è¡Œåº”è®¡ç®—I'm\\n\\\n",
    "ç¬¬äºŒè¡Œåº”è®¡ç®—so ä»¥æ­¤ç±»æ¨ å…¶ä»–è¯çš„å·®è·ä¸è¿›è¡Œè®¡ç®—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ad524-826f-4031-a18c-2736897cbbbd",
   "metadata": {},
   "source": [
    "## Multihead-Attention å†…éƒ¨æ•°æ®å¤„ç†çš„å˜åŒ–\n",
    "è™½ç„¶Transformerä¸­å·²ç»å®ç°è¿‡ä¸€éäº†ï¼Œä½†è¿™é‡Œä¸ºäº†æ–¹ä¾¿å±•ç¤ºï¼Œæ·»åŠ äº†ä¸€ä¸ªæ¯ä¸ªæ­¥éª¤è¾“å‡ºæ•°æ®å½¢çŠ¶\\\n",
    "æ–¹ä¾¿ç†è§£\\\n",
    "è¿™é‡Œæ˜¯ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "075040c5-c996-4a1e-8de1-adc99c2ebda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Attention_display(query, key, value, mask=None, dropout=None):\n",
    "    \"æ™®é€šçš„ç‚¹ç§¯å‹æ³¨æ„åŠ›\"\n",
    "    #è¾“å…¥çš„QKVçš„ç»´åº¦ä¸º(batch,head,quelen,d_k)d_kä¸ºåˆ†å¤´åçš„æ•°æ®\n",
    "    d_k = query.size(-1)\n",
    "    #åªå¯¹åä¸¤ç»´è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œä¿è¯å¤šå¤´æ³¨æ„åŠ›ï¼Œå„ä¸ªå¤´çš„æ•°æ®éš”ç¦»\n",
    "    print(\"A-è¿™æ—¶éœ€è¦è¿›è¡ŒQKç›¸ä¹˜çš„æ“ä½œ è¿™æ—¶QKçš„ç»´åº¦ä¸º:\",query.shape,key.shape)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    print(\"A-è¿™æ—¶å·²ç»å®ŒæˆQKç›¸ä¹˜çš„æ“ä½œï¼Œéœ€è¦å¯¹scoreçŸ©é˜µè¿›è¡Œmaskæ“ä½œ è¿™æ—¶Attention scoreçš„ç»´åº¦ä¸º:\",scores.shape)\n",
    "    if mask is not None:\n",
    "        #å¦‚æœæœ‰æ©ç ï¼Œåˆ™å°†æ•°æ®æ›¿æ¢ä¸º-1e9(æ¥è¿‘æ— ç©·å°)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    print(\"A-è¿™é‡Œå¦‚æœæœ‰æ©ç æ“ä½œçš„è¯ä¼šè¿›è¡Œæ©ç  è¿™æ—¶çš„scoreç»´åº¦æœªå˜åªæ˜¯æ•°æ®ä¸€éƒ¨åˆ†è¢«é®æ©æ‰äº†,ä¸æ–¹ä¾¿å±•ç¤º è¯·çœ‹ä¸‹é¢çš„maskå•ç‹¬çš„æ¼”ç¤º\")\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    print(\"A-è¿™é‡Œå¯¹æœ€åä¸€ä¸ªç»´åº¦çš„æ•°æ®è¿›è¡Œsoftmaxæ“ä½œ,æ­¤æ—¶scoreçš„ç»´åº¦ä¸º:\",scores.shape)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    print(\"A-è¿™é‡Œè¿›è¡Œäº†dropoutæ“ä½œç»´åº¦æœªå‘ç”Ÿæ”¹å˜\")\n",
    "    output = torch.matmul(p_attn, value)\n",
    "    print(\"A-è¿™è¿›è¡Œäº†å°†scoreä¸valueç›¸ä¹˜çš„è¿‡ç¨‹ æœ€ç»ˆè¾“å‡ºä¸º:\",output.shape)\n",
    "    return output, p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"éœ€è¦è¾“å…¥headæ•°ä»¥åŠd_model,headéœ€è¦å¯ä»¥æ•´é™¤d_model\"\n",
    "        \"å¤šå¤´çš„ç›®çš„æ˜¯è®©ä¸åŒçš„å¤´æå–çš„ç‰¹å¾ä¸åŒï¼Œä»¥ä¸°å¯Œæ¨¡å‹çš„ç‰¹å¾æå–\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # ç®—å‡ºåˆ†å¤šå¤´åçš„ç»´åº¦ å¦‚512ç»´ å…«å¤´ç»´åº¦å˜ä¸º(8,64)\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        #å¦‚æœæœ‰maskæ“ä½œåœ¨ç¬¬ä¸€ä¸ªç»´åº¦ååŠ å…¥ç»´åº¦\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # å…ˆåˆ†åˆ«å°†QKVåˆ†åˆ«è¾“å…¥çº¿æ€§å›å½’ä¸­ï¼Œç„¶åå°†å¾—åˆ°çš„QKVåˆ†åˆ«å°†ç»´åº¦åˆ’åˆ†å¤šå¤´\n",
    "        #shape=(batch,seqlen,d_model)->Linear(ç»´åº¦ä¸å˜)->(batch,head,seqlen,d_k)\n",
    "        query, key, value = [l(x) for l, x in zip(self.linears, (query, key, value))]\n",
    "        print(\"M-queryå…ˆè¿›å…¥ä¸€ä¸ªFNNï¼Œç»´åº¦ä¸æ”¹å˜ï¼ŒKVåŒç†  è¿™æ—¶queryç»´åº¦:\",query.shape)\n",
    "        query = query.view(nbatches, -1, self.h, self.d_k)\n",
    "        print(\"M-è¿™æ—¶queryè¿›è¡Œäº†åˆ†å¤´å˜æ¢ è¿™æ—¶çš„ç»´åº¦ä¸º:\",query.shape)\n",
    "        query = query.transpose(1, 2)\n",
    "        print(\"M-è¿™æ—¶queryè¿›è¡Œäº†ç»´åº¦äº¤æ¢ è¿™æ—¶çš„ç»´åº¦ä¸º:\",query.shape)\n",
    "        key = key.view(nbatches, -1, self.h, self.d_k)\n",
    "        key = key.transpose(1, 2)\n",
    "        value = value.view(nbatches, -1, self.h, self.d_k)\n",
    "        value = value.transpose(1, 2)\n",
    "        # å°†åˆ†å¥½å¤´çš„æ•°æ®è¾“å…¥Attentionï¼Œå¹¶å¾—å‡ºç»“æœ\n",
    "        print(\"M-è¿™æ—¶å°†å˜å½¢åçš„QKVä»¥åŠmaskè¾“å…¥Attention\")\n",
    "        x, self.attn = Attention_display(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) å°†æ•°æ®è¿˜åŸä¸ºåŸæ¥çš„æ ·å­ shape=(batch,seqlen,d_model)\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        print(\"M-è¿™é‡Œè¿›è¡Œäº†æ•°æ®ç»´åº¦çš„è¿˜åŸ è¿™æ—¶ç»´åº¦ä¸º:\",x.shape)\n",
    "        print(\"M-è¿™é‡Œå¯¹æœ€ç»ˆçš„è¾“å‡ºè¾“å…¥äº†ä¸€ä¸ªFNN ç»´åº¦æœªæ”¹å˜\")\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "def clones(module, N):\n",
    "    \"\"\"è¿™ä¸ªå‡½æ•°å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºæ•´ä¸ªç½‘ç»œç»“æ„æœ‰å¤šæ¬¡é‡å¤ç»“æ„ï¼Œå¯ä»¥ç”¨è¿™ä¸ªå‡½æ•°å¯¹å®ä¾‹è¿›è¡Œæ·±æ‹·è´ï¼Œä¾‹å¦‚å¯ä»¥å¤åˆ¶å¤šä¸ªEncoderæˆ–Linear\"\"\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eedb75b-775e-4cf6-a8cf-da6a8187c2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiHeadAttention è¾“å…¥: torch.Size([4, 4, 512])\n",
      "å¯¹åº”ç»´åº¦ä¸º (batchï¼Œè¯ä¸ªæ•°ï¼Œd_model)\n",
      "M-queryå…ˆè¿›å…¥ä¸€ä¸ªFNNï¼Œç»´åº¦ä¸æ”¹å˜ï¼ŒKVåŒç†  è¿™æ—¶queryç»´åº¦: torch.Size([4, 4, 512])\n",
      "M-è¿™æ—¶queryè¿›è¡Œäº†åˆ†å¤´å˜æ¢ è¿™æ—¶çš„ç»´åº¦ä¸º: torch.Size([4, 4, 8, 64])\n",
      "M-è¿™æ—¶queryè¿›è¡Œäº†ç»´åº¦äº¤æ¢ è¿™æ—¶çš„ç»´åº¦ä¸º: torch.Size([4, 8, 4, 64])\n",
      "M-è¿™æ—¶å°†å˜å½¢åçš„QKVä»¥åŠmaskè¾“å…¥Attention\n",
      "A-è¿™æ—¶éœ€è¦è¿›è¡ŒQKç›¸ä¹˜çš„æ“ä½œ è¿™æ—¶QKçš„ç»´åº¦ä¸º: torch.Size([4, 8, 4, 64]) torch.Size([4, 8, 4, 64])\n",
      "A-è¿™æ—¶å·²ç»å®ŒæˆQKç›¸ä¹˜çš„æ“ä½œï¼Œéœ€è¦å¯¹scoreçŸ©é˜µè¿›è¡Œmaskæ“ä½œ è¿™æ—¶Attention scoreçš„ç»´åº¦ä¸º: torch.Size([4, 8, 4, 4])\n",
      "A-è¿™é‡Œå¦‚æœæœ‰æ©ç æ“ä½œçš„è¯ä¼šè¿›è¡Œæ©ç  è¿™æ—¶çš„scoreç»´åº¦æœªå˜åªæ˜¯æ•°æ®ä¸€éƒ¨åˆ†è¢«é®æ©æ‰äº†,ä¸æ–¹ä¾¿å±•ç¤º è¯·çœ‹ä¸‹é¢çš„maskå•ç‹¬çš„æ¼”ç¤º\n",
      "A-è¿™é‡Œå¯¹æœ€åä¸€ä¸ªç»´åº¦çš„æ•°æ®è¿›è¡Œsoftmaxæ“ä½œ,æ­¤æ—¶scoreçš„ç»´åº¦ä¸º: torch.Size([4, 8, 4, 4])\n",
      "A-è¿™é‡Œè¿›è¡Œäº†dropoutæ“ä½œç»´åº¦æœªå‘ç”Ÿæ”¹å˜\n",
      "A-è¿™è¿›è¡Œäº†å°†scoreä¸valueç›¸ä¹˜çš„è¿‡ç¨‹ æœ€ç»ˆè¾“å‡ºä¸º: torch.Size([4, 8, 4, 64])\n",
      "M-è¿™é‡Œè¿›è¡Œäº†æ•°æ®ç»´åº¦çš„è¿˜åŸ è¿™æ—¶ç»´åº¦ä¸º: torch.Size([4, 4, 512])\n",
      "M-è¿™é‡Œå¯¹æœ€ç»ˆçš„è¾“å‡ºè¾“å…¥äº†ä¸€ä¸ªFNN ç»´åº¦æœªæ”¹å˜\n",
      "MultiHeadAttentionè¾“å‡º torch.Size([4, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#å®ä¾‹åŒ–ä¸€ä¸ªMultiHeadattention\n",
    "ma = MultiHeadedAttention(8,512)\n",
    "#æ•°æ®ä½¿ç”¨å‰é¢\n",
    "input_data =  pe(en_embedding(trg_input))\n",
    "print('MultiHeadAttention è¾“å…¥:',input_data.shape)\n",
    "print('å¯¹åº”ç»´åº¦ä¸º (batchï¼Œè¯ä¸ªæ•°ï¼Œd_model)')\n",
    "output = ma(input_data,input_data,input_data,b1.trg_mask)\n",
    "print('MultiHeadAttentionè¾“å‡º',output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ba7f3",
   "metadata": {},
   "source": [
    "## mask å±•ç¤º\n",
    "ä¸‹é¢å±•ç¤ºä»¥ä¸‹maskåçš„decoderè¾“å…¥\n",
    "è¿™ä¸ªæ“ä½œå…¶å®æ˜¯åœ¨attentionä¸­æ‰§è¡Œçš„ï¼Œè¿™é‡Œåªæ˜¯ç®€å•å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cc12b65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698],\n",
      "        [  1,  23, 175, 698]])\n",
      "-------------------------------------------------\n",
      "tensor([[[          1, -1000000000, -1000000000, -1000000000],\n",
      "         [          1,          23, -1000000000, -1000000000],\n",
      "         [          1,          23,         175, -1000000000],\n",
      "         [          1,          23,         175,         698]]])\n"
     ]
    }
   ],
   "source": [
    "print(trg_input)\n",
    "print(\"-------------------------------------------------\")\n",
    "print(trg_input.masked_fill(b1.trg_mask==0,-1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34680f4b",
   "metadata": {},
   "source": [
    "## ä»¥ä¸Šä¸ºä¸€æ¡æ•°æ®å…¨éƒ¨æµç¨‹\n",
    "è¿™é‡Œæ²¡æœ‰æ¼”ç¤ºæŸå¤±å‡½æ•°è®¡ç®—ä»¥åŠä¼˜åŒ–è¿‡ç¨‹ï¼ŒæŸå¤±å‡½æ•°å“ˆä½›å­¦ä¹ ç‰ˆä½¿ç”¨äº†KLæ•£åº¦ï¼Œè€Œattentionè®ºæ–‡ä¸­ä½¿ç”¨äº†äº¤å‰ç†µï¼Œè¿™é‡Œä¸åšè¯„ä»·ï¼Œè¯·è‡ªè¡Œé€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°\\\n",
    "Transformerçš„ä¼˜åŒ–æ˜¯å¸¦æœ‰çƒ­èº«çš„ï¼Œ1ä¸ªå°æ—¶è¿çƒ­èº«éƒ½è·‘ä¸å®Œï¼Œæ‰€ä»¥å°±ç®—äº†\\\n",
    "ä¸€æ¡æ•°æ®çš„å¦‚ä½•å¤„ç†å¦‚ä½•èµ°è¿‡æ•´ä¸ªæ¨¡å‹çš„æ ·å­å·²ç»æ¼”ç¤ºäº†\\\n",
    "ç›¸ä¿¡ä½ è‚¯å®šä¼šæ‰¹é‡è®­ç»ƒäº†å§ğŸ¤¡\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2.1.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
